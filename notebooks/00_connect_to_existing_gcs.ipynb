{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ba87c5-8e6b-41ba-a223-334237015a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… google-cloud-storage already installed\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 1: Install Required Package (if needed)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from google.cloud import storage\n",
    "    print(\"âœ… google-cloud-storage already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing google-cloud-storage...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"google-cloud-storage\"])\n",
    "    print(\"âœ… Installation complete. Please restart kernel if needed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8784d34-9e7c-41be-be7c-5d51f8d9f2d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (629497118.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython -m pip install --upgrade pip\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d16dcca-4a10-45a6-aa22-696b066af127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/sarahdavidson/posner_quantum_dynamics/venv/lib/python3.12/site-packages (25.0.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0.1\n",
      "    Uninstalling pip-25.0.1:\n",
      "      Successfully uninstalled pip-25.0.1\n",
      "Successfully installed pip-25.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00996b79-b210-4984-8958-8935432368c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Setting up Google Cloud Authentication\n",
      "\n",
      "Choose your authentication method:\n",
      "\n",
      "1. Use existing gcloud CLI authentication (if you're already logged in)\n",
      "2. Use a service account JSON key file\n",
      "3. Set up new authentication\n",
      "âœ… Found existing authentication for project: quantum-sfa-phd\n",
      "\n",
      "âœ… Already authenticated with project: quantum-sfa-phd\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 2: Set Up Authentication\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "print(\"ðŸ” Setting up Google Cloud Authentication\\n\")\n",
    "print(\"Choose your authentication method:\\n\")\n",
    "print(\"1. Use existing gcloud CLI authentication (if you're already logged in)\")\n",
    "print(\"2. Use a service account JSON key file\")\n",
    "print(\"3. Set up new authentication\")\n",
    "\n",
    "# Check if already authenticated via gcloud\n",
    "def check_gcloud_auth():\n",
    "    \"\"\"Check if gcloud is already authenticated\"\"\"\n",
    "    try:\n",
    "        from google.auth import default\n",
    "        credentials, project = default()\n",
    "        print(f\"âœ… Found existing authentication for project: {project}\")\n",
    "        return True, project\n",
    "    except Exception as e:\n",
    "        return False, None\n",
    "\n",
    "is_authenticated, project_id = check_gcloud_auth()\n",
    "\n",
    "if is_authenticated:\n",
    "    print(f\"\\nâœ… Already authenticated with project: {project_id}\")\n",
    "    USE_EXISTING_AUTH = True\n",
    "else:\n",
    "    print(\"\\nâŒ No existing authentication found\")\n",
    "    print(\"Please choose option 2 or 3 above\")\n",
    "    USE_EXISTING_AUTH = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee299d8-fbb0-447d-9861-15444c3a8ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 1: Import Required Libraries\n",
    "from google.cloud import storage\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33384311-6776-4fe6-ab1b-e727e2bd8753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¦ Configured buckets:\n",
      "  - results: quantum-sfa-results\n",
      "  - data: quantum-sfa-data\n",
      "  - archive: quantum-sfa-archive\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 2: Define Configuration (THIS WAS MISSING!)\n",
    "\"\"\"\n",
    "Define all your bucket names and project configuration\n",
    "\"\"\"\n",
    "\n",
    "# Your bucket configuration - DEFINE THIS FIRST\n",
    "BUCKETS = {\n",
    "    'results': 'quantum-sfa-results',\n",
    "    'data': 'quantum-sfa-data',\n",
    "    'archive': 'quantum-sfa-archive'\n",
    "}\n",
    "\n",
    "PROJECT_ID = 'quantum-brain-models'  # Update if your project ID is different\n",
    "\n",
    "print(\"ðŸ“¦ Configured buckets:\")\n",
    "for purpose, bucket_name in BUCKETS.items():\n",
    "    print(f\"  - {purpose}: {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "722c97bb-5d6e-4c02-9233-278ee71a0697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Testing connections to your buckets:\n",
      "\n",
      "\n",
      "Testing results bucket:\n",
      "âœ… Connected to: quantum-sfa-results\n",
      "   Contains items (showing max 3):\n",
      "   - model4/Test1_PNC_Baseline_20250823_062949/data.json (0.1 KB)\n",
      "   - model4/Test1_PNC_Baseline_20250823_063329/data.json (0.1 KB)\n",
      "   - model4/Test1_PNC_Baseline_20250823_063555/data.json (0.1 KB)\n",
      "----------------------------------------\n",
      "\n",
      "Testing data bucket:\n",
      "âœ… Connected to: quantum-sfa-data\n",
      "   Contains items (showing max 3):\n",
      "   - (bucket is empty)\n",
      "----------------------------------------\n",
      "\n",
      "Testing archive bucket:\n",
      "âœ… Connected to: quantum-sfa-archive\n",
      "   Contains items (showing max 3):\n",
      "   - (bucket is empty)\n",
      "----------------------------------------\n",
      "\n",
      "ðŸŽ‰ All buckets connected successfully!\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 3: Test Connection to Your Buckets\n",
    "\"\"\"\n",
    "Now test access to each bucket\n",
    "\"\"\"\n",
    "\n",
    "def test_bucket_access(bucket_name):\n",
    "    \"\"\"Test access to a specific bucket\"\"\"\n",
    "    try:\n",
    "        client = storage.Client(project=PROJECT_ID)\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        \n",
    "        # List first few items to verify access\n",
    "        blobs = list(bucket.list_blobs(max_results=3))\n",
    "        \n",
    "        print(f\"âœ… Connected to: {bucket_name}\")\n",
    "        print(f\"   Contains items (showing max 3):\")\n",
    "        \n",
    "        if len(blobs) == 0:\n",
    "            print(f\"   - (bucket is empty)\")\n",
    "        else:\n",
    "            for blob in blobs:\n",
    "                size_kb = blob.size / 1024 if blob.size else 0\n",
    "                print(f\"   - {blob.name} ({size_kb:.1f} KB)\")\n",
    "        \n",
    "        return bucket\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to connect to {bucket_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"ðŸ”„ Testing connections to your buckets:\\n\")\n",
    "connected_buckets = {}\n",
    "\n",
    "for purpose, bucket_name in BUCKETS.items():\n",
    "    print(f\"\\nTesting {purpose} bucket:\")\n",
    "    connected_buckets[purpose] = test_bucket_access(bucket_name)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "if all(connected_buckets.values()):\n",
    "    print(\"\\nðŸŽ‰ All buckets connected successfully!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Some buckets failed to connect. Check permissions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee18154f-9ce9-4552-bc39-ffa654ba4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Initializing Storage Manager...\n",
      "âœ… Storage Manager initialized for project: quantum-brain-models\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 4: Create the Storage Manager Class\n",
    "\"\"\"\n",
    "Unified manager for all your GCS operations\n",
    "\"\"\"\n",
    "\n",
    "class QuantumSFAStorage:\n",
    "    \"\"\"Manager for your Quantum-SFA storage buckets\"\"\"\n",
    "    \n",
    "    def __init__(self, project_id=None):\n",
    "        self.project_id = project_id or PROJECT_ID\n",
    "        self.client = storage.Client(project=self.project_id)\n",
    "        \n",
    "        # Connect to your three buckets\n",
    "        self.results_bucket = self.client.bucket(BUCKETS['results'])\n",
    "        self.data_bucket = self.client.bucket(BUCKETS['data'])\n",
    "        self.archive_bucket = self.client.bucket(BUCKETS['archive'])\n",
    "        \n",
    "        print(f\"âœ… Storage Manager initialized for project: {self.project_id}\")\n",
    "        \n",
    "    def save_model_results(self, model_name, results_dict, experiment_tag=None):\n",
    "        \"\"\"\n",
    "        Save model results to the results bucket\n",
    "        \n",
    "        Args:\n",
    "            model_name: e.g., 'model4_dynamic_nanoreactor'\n",
    "            results_dict: Dictionary containing your results\n",
    "            experiment_tag: Optional tag for this experiment\n",
    "        \"\"\"\n",
    "        # Create organized path structure\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        date_folder = datetime.now().strftime('%Y_%m_%d')\n",
    "        \n",
    "        if experiment_tag:\n",
    "            filename = f\"{model_name}_{experiment_tag}_{timestamp}.json\"\n",
    "        else:\n",
    "            filename = f\"{model_name}_{timestamp}.json\"\n",
    "            \n",
    "        # Path: results/YYYY_MM_DD/model_name/filename\n",
    "        blob_path = f\"results/{date_folder}/{model_name}/{filename}\"\n",
    "        \n",
    "        # Upload to results bucket\n",
    "        blob = self.results_bucket.blob(blob_path)\n",
    "        blob.upload_from_string(\n",
    "            json.dumps(results_dict, indent=2, default=str),\n",
    "            content_type='application/json'\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Saved to: gs://{BUCKETS['results']}/{blob_path}\")\n",
    "        return blob_path\n",
    "    \n",
    "    def save_raw_data(self, data, data_type, description):\n",
    "        \"\"\"Save raw data (arrays, etc.) to the data bucket\"\"\"\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        blob_path = f\"{data_type}/{description}_{timestamp}.pkl\"\n",
    "        \n",
    "        blob = self.data_bucket.blob(blob_path)\n",
    "        \n",
    "        # Save as pickle for complex data structures\n",
    "        blob.upload_from_string(pickle.dumps(data))\n",
    "        \n",
    "        print(f\"âœ… Raw data saved to: gs://{BUCKETS['data']}/{blob_path}\")\n",
    "        return blob_path\n",
    "    \n",
    "    def list_recent_results(self, model_name=None, limit=10):\n",
    "        \"\"\"List recent results from the results bucket\"\"\"\n",
    "        prefix = \"results/\"\n",
    "        if model_name:\n",
    "            # Note: This won't perfectly filter by model name due to path structure\n",
    "            # but will show recent results\n",
    "            pass\n",
    "            \n",
    "        blobs = self.results_bucket.list_blobs(prefix=prefix, max_results=limit)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Recent Results (max {limit}):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        results = []\n",
    "        for blob in blobs:\n",
    "            # Parse the path to get meaningful info\n",
    "            parts = blob.name.split('/')\n",
    "            if len(parts) >= 3:\n",
    "                date = parts[1] if len(parts) > 1 else \"unknown\"\n",
    "                model = parts[2] if len(parts) > 2 else \"unknown\"\n",
    "                file = parts[-1] if len(parts) > 3 else blob.name\n",
    "                \n",
    "                print(f\"  {date} | {model}\")\n",
    "                print(f\"    â””â”€ {file}\")\n",
    "                \n",
    "                results.append({\n",
    "                    'path': blob.name,\n",
    "                    'created': blob.time_created,\n",
    "                    'size': blob.size\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def load_result(self, blob_path):\n",
    "        \"\"\"Load a specific result from storage\"\"\"\n",
    "        blob = self.results_bucket.blob(blob_path)\n",
    "        \n",
    "        if blob.exists():\n",
    "            content = blob.download_as_text()\n",
    "            return json.loads(content)\n",
    "        else:\n",
    "            print(f\"âŒ Not found: {blob_path}\")\n",
    "            return None\n",
    "    \n",
    "    def today_results(self):\n",
    "        \"\"\"Show all results from today\"\"\"\n",
    "        date_folder = datetime.now().strftime('%Y_%m_%d')\n",
    "        prefix = f\"results/{date_folder}/\"\n",
    "        \n",
    "        blobs = self.results_bucket.list_blobs(prefix=prefix)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Today's Results ({date_folder}):\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        count = 0\n",
    "        for blob in blobs:\n",
    "            # Extract meaningful name from path\n",
    "            parts = blob.name.split('/')\n",
    "            if len(parts) >= 4:\n",
    "                model = parts[2]\n",
    "                filename = parts[3]\n",
    "                print(f\"  {model}: {filename}\")\n",
    "                count += 1\n",
    "        \n",
    "        if count == 0:\n",
    "            print(\"  (No results yet today)\")\n",
    "        else:\n",
    "            print(f\"\\nTotal: {count} results today\")\n",
    "        \n",
    "        return count\n",
    "\n",
    "# Initialize the storage manager\n",
    "print(\"\\nðŸ”„ Initializing Storage Manager...\")\n",
    "storage_manager = QuantumSFAStorage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af172ce-989b-41a5-8797-fc90167d781b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Posner Quantum",
   "language": "python",
   "name": "posner_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
